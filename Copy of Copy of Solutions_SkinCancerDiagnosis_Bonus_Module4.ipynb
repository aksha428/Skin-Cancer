{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1m9RBnGP3LK38JRhJHx_-xM0VEn-kP4j3","timestamp":1687335705809},{"file_id":"1Ca66mlaiqz1B6jRgjvahaPqfvKLTVamz","timestamp":1684623497160}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ih8pc-WDIxbx","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1687337747168,"user_tz":300,"elapsed":214676,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}},"outputId":"9ff5f424-f7bd-4c35-d8ad-879e12e16151"},"source":["!pip install -U folium==0.2.1\n","!pip install -U packaging==20.9\n","!pip install -U opencv-contrib-python\n","\n","import cv2\n","from google.colab.output import eval_js\n","import time\n","start_time = time.time()\n","\n","from tqdm.notebook import tqdm\n","import tensorflow.keras as keras\n","!pip install git+https://github.com/rdk2132/scikeras  # workaround for scikeras deprecation\n","import scikeras\n","from scikeras.wrappers import KerasClassifier\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Reshape, add, concatenate, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import seaborn as sns\n","import os\n","import random\n","from PIL import Image\n","import gdown\n","import argparse\n","import numpy as np\n","import struct\n","from google.colab.patches import cv2_imshow\n","from copy import deepcopy\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import tree\n","from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_auc_score\n","from sklearn.base import BaseEstimator\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.metrics import make_scorer, accuracy_score\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","!pip install hypopt\n","from hypopt import GridSearch\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import KMeans, AgglomerativeClustering\n","!pip install tensorflowjs\n","import tensorflowjs as tfjs\n","from google.colab import files\n","import requests, io, zipfile\n","\n","# Prepare data\n","images_1 = os.makedirs('images_1', exist_ok=True)\n","images_2 = os.makedirs('images_2', exist_ok=True)\n","images_all = os.makedirs('images_all', exist_ok=True)\n","\n","metadata_path = 'metadata.csv'\n","image_path_1 = 'images_1.zip'\n","image_path_2 = 'images_2.zip'\n","images_rgb_path = 'hmnist_8_8_RGB.csv'\n","\n","!wget -O metadata.csv 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/metadata.csv'\n","!wget -O images_1.zip 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/images_1.zip'\n","!wget -O images_2.zip 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/images_2.zip'\n","!wget -O hmnist_8_8_RGB.csv 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/hmnist_8_8_RGB.csv'\n","!unzip -q -o images_1.zip -d images_1\n","!unzip -q -o images_2.zip -d images_2\n","\n","!pip install patool\n","import patoolib\n","\n","import os.path\n","from os import path\n","\n","from distutils.dir_util import copy_tree\n","\n","fromDirectory = 'images_1'\n","toDirectory = 'images_all'\n","\n","copy_tree(fromDirectory, toDirectory)\n","\n","fromDirectory = 'images_2'\n","toDirectory = 'images_all'\n","\n","copy_tree(fromDirectory, toDirectory)\n","\n","os.makedirs(\"static/js\")\n","!wget -O static/js/skin_cancer_diagnosis_script.js 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/skin_cancer_diagnosis_script.js'\n","output = 'static/js/skin_cancer_diagnosis_script.js'\n","\n","print(\"Downloaded Data\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.10/dist-packages (0.2.1)\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from folium==0.2.1) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->folium==0.2.1) (2.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: packaging==20.9 in /usr/local/lib/python3.10/dist-packages (20.9)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging==20.9) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.22.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/rdk2132/scikeras\n","  Cloning https://github.com/rdk2132/scikeras to /tmp/pip-req-build-m8pfhig8\n","  Running command git clone --filter=blob:none --quiet https://github.com/rdk2132/scikeras /tmp/pip-req-build-m8pfhig8\n","  Resolved https://github.com/rdk2132/scikeras to commit b7a2ce5487b2a0164e6be7f5172a894859eebb03\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras==0.8.0) (20.9)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras==0.8.0) (1.2.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging<22.0,>=0.21->scikeras==0.8.0) (3.0.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras==0.8.0) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras==0.8.0) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras==0.8.0) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras==0.8.0) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: hypopt in /usr/local/lib/python3.10/dist-packages (1.0.9)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from hypopt) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from hypopt) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->hypopt) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->hypopt) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->hypopt) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.10/dist-packages (4.8.0)\n","Requirement already satisfied: flax<0.6.3,>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.6.2)\n","Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (5.12.0)\n","Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.10)\n","Requirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.12.0)\n","Requirement already satisfied: tensorflow-decision-forests>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.3.0)\n","Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n","Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.13.0)\n","Requirement already satisfied: packaging~=20.9 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (20.9)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (3.7.1)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.5)\n","Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.5)\n","Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.36)\n","Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (13.3.4)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.5.0)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (6.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (0.1.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.8.0)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (67.7.2)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (1.5.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n","Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (3.0.3)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.14.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (8.4.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n","Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.7)\n","Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.4.10+cuda11.cudnn86)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2022.7.1)\n","Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.8)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.12.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n","--2023-06-21 08:52:47--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/metadata.csv\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.128, 142.251.175.128, 172.253.118.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 553377 (540K) [text/csv]\n","Saving to: ‘metadata.csv’\n","\n","metadata.csv        100%[===================>] 540.41K   990KB/s    in 0.5s    \n","\n","2023-06-21 08:52:47 (990 KB/s) - ‘metadata.csv’ saved [553377/553377]\n","\n","--2023-06-21 08:52:47--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/images_1.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.128, 142.251.175.128, 172.253.118.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1366522108 (1.3G) [application/zip]\n","Saving to: ‘images_1.zip’\n","\n","images_1.zip        100%[===================>]   1.27G  19.6MB/s    in 62s     \n","\n","2023-06-21 08:53:50 (21.0 MB/s) - ‘images_1.zip’ saved [1366522108/1366522108]\n","\n","--2023-06-21 08:53:50--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/images_2.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.175.128, 172.253.118.128, 74.125.24.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.175.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1403566547 (1.3G) [application/zip]\n","Saving to: ‘images_2.zip’\n","\n","images_2.zip        100%[===================>]   1.31G  19.2MB/s    in 72s     \n","\n","2023-06-21 08:55:03 (18.6 MB/s) - ‘images_2.zip’ saved [1403566547/1403566547]\n","\n","--2023-06-21 08:55:03--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/hmnist_8_8_RGB.csv\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 142.251.10.128, 142.251.12.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7524968 (7.2M) [text/csv]\n","Saving to: ‘hmnist_8_8_RGB.csv’\n","\n","hmnist_8_8_RGB.csv  100%[===================>]   7.18M  6.06MB/s    in 1.2s    \n","\n","2023-06-21 08:55:04 (6.06 MB/s) - ‘hmnist_8_8_RGB.csv’ saved [7524968/7524968]\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: patool in /usr/local/lib/python3.10/dist-packages (1.12)\n"]},{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c6a169a5bc5f>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mcopy_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromDirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoDirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"static/js\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wget -O static/js/skin_cancer_diagnosis_script.js 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/skin_cancer_diagnosis_script.js'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'static/js/skin_cancer_diagnosis_script.js'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'static/js'"]}]},{"cell_type":"code","metadata":{"id":"ITfh4GjlttRH","executionInfo":{"status":"aborted","timestamp":1687337747169,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["IMG_WIDTH = 100\n","IMG_HEIGHT = 75"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LX1w_FIuv26r","executionInfo":{"status":"aborted","timestamp":1687337747169,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["metadata = pd.read_csv(metadata_path)\n","metadata['category'] = metadata['dx'].replace({'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6,})\n","\n","X = []\n","X_g = []\n","y = []\n","\n","for i in tqdm(range(len(metadata))):\n","  image_meta = metadata.iloc[i]\n","  path = os.path.join(toDirectory, image_meta['image_id'] + '.jpg')\n","  img = cv2.imread(path,cv2.IMREAD_COLOR)\n","  img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT))\n","\n","  img_g = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","  X_g.append(img_g)\n","\n","  X.append(img)\n","  y.append(image_meta['category'])\n","\n","X_g = np.array(X_g)\n","X = np.array(X)\n","y = np.array(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yvxpG1LB2Ig","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["sample_cap = 142\n","option = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAZqqMTgnmOq","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["if (option == 1):\n","  objects = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n","  class_totals = [0,0,0,0,0,0,0]\n","  iter_samples = [0,0,0,0,0,0,0]\n","  indicies = []\n","\n","  for i in range(len(X)):\n","    class_totals[y[i]] += 1\n","\n","  print(\"Initial Class Samples\")\n","  print(class_totals)\n","\n","  for i in range(len(X)):\n","    if iter_samples[y[i]] != sample_cap:\n","      indicies.append(i)\n","      iter_samples[y[i]] += 1\n","\n","  X = X[indicies]\n","  X_g = X_g[indicies]\n","\n","  y = y[indicies]\n","\n","  class_totals = [0,0,0,0,0,0,0]\n","\n","  for i in range(len(X)):\n","    class_totals[y[i]] += 1\n","\n","  print(\"Modified Class Samples\")\n","  print(class_totals)\n","else:\n","  print(\"This option was not selected\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UC4VupwgyqpN","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n","X_g_train, X_g_test, y_train, y_test = train_test_split(X_g, y, test_size=0.4, random_state=101)\n","\n","X_augmented = []\n","X_g_augmented = []\n","\n","y_augmented = []\n","\n","for i in tqdm(range(len(X_train))):\n","  transform = random.randint(0,1)\n","  if (transform == 0):\n","    # Flip the image across the y-axis\n","    X_augmented.append(cv2.flip(X_train[i],1))\n","    X_g_augmented.append(cv2.flip(X_g_train[i],1))\n","    y_augmented.append(y_train[i])\n","  else:\n","    # Zoom 33% into the image\n","    zoom = 0.33\n","\n","    centerX,centerY=int(IMG_HEIGHT/2),int(IMG_WIDTH/2)\n","    radiusX,radiusY= int((1-zoom)*IMG_HEIGHT*2),int((1-zoom)*IMG_WIDTH*2)\n","\n","    minX,maxX=centerX-radiusX,centerX+radiusX\n","    minY,maxY=centerY-radiusY,centerY+radiusY\n","\n","    cropped = (X_train[i])[minX:maxX, minY:maxY]\n","    new_img = cv2.resize(cropped, (IMG_WIDTH, IMG_HEIGHT))\n","    X_augmented.append(new_img)\n","\n","    cropped = (X_g_train[i])[minX:maxX, minY:maxY]\n","    new_img = cv2.resize(cropped, (IMG_WIDTH, IMG_HEIGHT))\n","    X_g_augmented.append(new_img)\n","\n","    y_augmented.append(y_train[i])\n","\n","X_augmented = np.array(X_augmented)\n","X_g_augmented = np.array(X_g_augmented)\n","\n","y_augmented = np.array(y_augmented)\n","\n","X_train = np.vstack((X_train,X_augmented))\n","X_g_train = np.vstack((X_g_train,X_g_augmented))\n","\n","y_train = np.append(y_train,y_augmented)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rAxZLYq-Mog1","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["colors = ['red','green','blue','purple','black','brown','orange']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h43Ghnpcw5yM","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWIVZC-D0uOX","executionInfo":{"status":"aborted","timestamp":1687337747170,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_flat = X.reshape(X.shape[0],X.shape[1]*X.shape[2]*X.shape[3])\n","X_g_flat = X_g.reshape(X_g.shape[0],X_g.shape[1]*X_g.shape[2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bAjFDB3Iwcb","executionInfo":{"status":"aborted","timestamp":1687337747171,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["pca = PCA(n_components=2)\n","X_pca = pca.fit_transform(X_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2Xe7UqSFxuA","executionInfo":{"status":"aborted","timestamp":1687337747171,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap=matplotlib.colors.ListedColormap(colors))\n","cb = plt.colorbar()\n","loc = np.arange(0,max(y),max(y)/float(len(colors)))\n","cb.set_ticks(loc)\n","cb.set_ticklabels(classes)\n","plt.title(\"PCA Representation\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6k3T4o6p3aKG","executionInfo":{"status":"aborted","timestamp":1687337747171,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def plot_visualization(X,y,colors,classes,name):\n","  plt.scatter(X[:,0], X[:,1], c=y, cmap=matplotlib.colors.ListedColormap(colors))\n","  cb = plt.colorbar()\n","  loc = np.arange(0,max(y),max(y)/float(len(colors)))\n","  cb.set_ticks(loc)\n","  cb.set_ticklabels(classes)\n","  plt.title(name)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chtkg0tiIn4f","executionInfo":{"status":"aborted","timestamp":1687337747171,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["tsne = TSNE(n_components=2,init=\"random\",learning_rate=200.0)\n","X_tsne = tsne.fit_transform(X_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CcBXcQxeuYO","executionInfo":{"status":"aborted","timestamp":1687337747171,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["plt.scatter(X_tsne[:,0], X_tsne[:,1], c=y, cmap=matplotlib.colors.ListedColormap(colors))\n","cb = plt.colorbar()\n","loc = np.arange(0,max(y),max(y)/float(len(colors)))\n","cb.set_ticks(loc)\n","cb.set_ticklabels(classes)\n","plt.title(\"T-SNE Representation\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Lb2RO6psr5x","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["lesion_img = X_g[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaQ_Xuk9IJi2","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["sift = cv2.xfeatures2d.SIFT_create()\n","keypoints, descriptor = sift.detectAndCompute(lesion_img,None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7QDzSeNsxpH","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["sift_img = cv2.drawKeypoints(X[0],keypoints,lesion_img)\n","cv2_imshow(sift_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yR1jIGjBPDR5","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(descriptor.shape)\n","print(descriptor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUS3ZQwznq3r","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["all_descriptors = []\n","\n","for i in tqdm(range(X_train.shape[0])):\n","  kp, des = sift.detectAndCompute(X_train[i], None)\n","\n","  if des is not None:\n","    for d in des:\n","      all_descriptors.append(d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKvtmYRmpWof","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(len(all_descriptors))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2ksRzKFr3jp","executionInfo":{"status":"aborted","timestamp":1687337747172,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["k = len(classes)*10\n","\n","sift_kmeans = KMeans(n_clusters=k)\n","sift_kmeans.fit(all_descriptors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zC_fjZvzo1Fd","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_sift_train = []\n","y_sift_train = []\n","\n","for i in tqdm(range(X_train.shape[0])):\n","  kp, des = sift.detectAndCompute(X_train[i], None)\n","\n","  sift_sample = np.zeros(k)\n","  nkp = np.size(kp)\n","\n","  if des is not None:\n","    for d in des:\n","      idx = sift_kmeans.predict([d])\n","      sift_sample[idx] += 1/nkp\n","\n","    X_sift_train.append(sift_sample)\n","    y_sift_train.append(y_train[i])\n","\n","X_sift_train = np.array(X_sift_train)\n","y_sift_train = np.array(y_sift_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJXvU37j1dyw","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_sift_test = []\n","y_sift_test = []\n","\n","for i in tqdm(range(X_test.shape[0])):\n","  # Your Code Here\n","  kp, des = sift.detectAndCompute(X_test[i], None)\n","\n","  sift_sample = np.zeros(k)\n","  nkp = np.size(kp)\n","\n","  if des is not None:\n","    for d in des:\n","      idx = sift_kmeans.predict([d])\n","      sift_sample[idx] += 1/nkp\n","\n","    X_sift_test.append(sift_sample)\n","    y_sift_test.append(y_train[i])\n","\n","X_sift_test = np.array(X_sift_test)\n","y_sift_test = np.array(y_sift_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDz-_m1hsbUG","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["sift_mlp = MLPClassifier(random_state=101, max_iter=900000)\n","sift_mlp.fit(X_sift_train,y_sift_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdgFEDo82dYQ","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def model_stats(name, y_test, y_pred, y_pred_proba):\n","  cm = confusion_matrix(y_test, y_pred)\n","\n","  print(name)\n","\n","  accuracy = accuracy_score(y_test,y_pred)\n","  print (\"The accuracy of the model is \" + str(round(accuracy,5)))\n","\n","  roc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n","\n","  print (\"The ROC AUC Score of the model is \" + str(round(roc_score,5)))\n","\n","  return cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4dV5WiZttAQ","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":12,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["y_pred = sift_mlp.predict(X_sift_test)\n","y_pred_proba = sift_mlp.predict_proba(X_sift_test)\n","\n","sift_cm = model_stats(\"SIFT MLP Model\",y_sift_test,y_pred,y_pred_proba)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHweJLDq2hJO","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def plot_cm(name, cm):\n","  classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n","\n","  df_cm = pd.DataFrame(cm, index = [i for i in classes], columns = [i for i in classes])\n","  df_cm = df_cm.round(5)\n","\n","  plt.figure(figsize = (12,8))\n","  sns.heatmap(df_cm, annot=True, fmt='g')\n","  plt.title(name + \" Model Confusion Matrix\")\n","  plt.xlabel(\"Predicted Label\")\n","  plt.ylabel(\"True Label\")\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDTNCB6nvF05","executionInfo":{"status":"aborted","timestamp":1687337747173,"user_tz":300,"elapsed":11,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n","\n","df_cm = pd.DataFrame(sift_cm, index = [i for i in classes], columns = [i for i in classes])\n","df_cm = df_cm.round(5)\n","\n","plt.figure(figsize = (12,8))\n","sns.heatmap(df_cm, annot=True, fmt='g')\n","plt.title(\"SIFT Model Confusion Matrix\")\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_673XUY2zp_","executionInfo":{"status":"aborted","timestamp":1687337747175,"user_tz":300,"elapsed":13,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_sift = np.vstack((X_sift_train,X_sift_test))\n","y_sift = np.append(y_sift_train,y_sift_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQv_K5qX3IDS","executionInfo":{"status":"aborted","timestamp":1687337747175,"user_tz":300,"elapsed":214967,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["sift_tsne = TSNE(n_components=2,init=\"random\",learning_rate=200.0)\n","X_sift_tsne = sift_tsne.fit_transform(X_sift)\n","\n","colors = ['red','green','blue','purple','black','brown','orange']\n","classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n","\n","plot_visualization(X_sift_tsne,y_sift,colors,classes,\"T-SNE Representation\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJyNR4L-zNv6","executionInfo":{"status":"aborted","timestamp":1687337747175,"user_tz":300,"elapsed":214966,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["IMGS_TO_CHECK = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY3V2s-NFXYc","executionInfo":{"status":"aborted","timestamp":1687337747175,"user_tz":300,"elapsed":214964,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["from ipywidgets import interact\n","import ipywidgets as widgets\n","def plot_thing(image_index):\n","  lesion_img = X_g[image_index]\n","  ret2,otsu_img = cv2.threshold(lesion_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","  cv2_imshow(X[image_index])\n","  cv2_imshow(otsu_img)\n","interact(plot_thing, image_index=widgets.IntSlider(min=0, max= IMGS_TO_CHECK - 1, step=1))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlcur0uIv32-","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214964,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"K Means Clustering\")\n","kmlist = []\n","for i in range(IMGS_TO_CHECK):\n","  lesion_img = X[i]\n","\n","  lesion_img_flat = lesion_img.reshape(lesion_img.shape[0]*lesion_img.shape[1],lesion_img.shape[2])\n","\n","  kmeans = KMeans(n_clusters=2, random_state=101)\n","  kmeans_labels = kmeans.fit_predict(lesion_img_flat)\n","\n","  for j in range(len(kmeans_labels)):\n","    if kmeans_labels[j] == 1:\n","      kmeans_labels[j] = 255\n","\n","  kmeans_lesion_img = kmeans_labels.reshape(IMG_HEIGHT,IMG_WIDTH)\n","  kmlist.append(kmeans_lesion_img)\n","\n","def plot_thing(image_index):\n","  lesion_img = X_g[image_index]\n","  kmeans_lesion_img = kmlist[image_index]\n","  cv2_imshow(lesion_img)\n","  cv2_imshow(kmeans_lesion_img)\n","\n","interact(plot_thing, image_index=widgets.IntSlider(min=0, max=IMGS_TO_CHECK - 1, step=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dK6eb43e2YdF","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214963,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["lesion_img = X[0]\n","lesion_img_flat = lesion_img.reshape(lesion_img.shape[0]*lesion_img.shape[1],lesion_img.shape[2])\n","\n","kmeans = KMeans(n_clusters=2, random_state=101)\n","kmeans_labels = kmeans.fit_predict(lesion_img_flat)\n","\n","for i in range(len(kmeans_labels)):\n","  if kmeans_labels[i] == 1:\n","    kmeans_labels[i] = 255\n","\n","# Your Code Here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yeo6M9ZH5NRh","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214962,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["lesion_img = X[0]\n","lesion_img_flat = lesion_img.reshape(lesion_img.shape[0]*lesion_img.shape[1],lesion_img.shape[2])\n","\n","kmeans = KMeans(n_clusters=2, random_state=101)\n","kmeans_labels = kmeans.fit_predict(lesion_img_flat)\n","\n","for i in range(len(kmeans_labels)):\n","  if kmeans_labels[i] == 1:\n","    kmeans_labels[i] = 255\n","\n","tsne = TSNE(n_components=2,init='random',learning_rate=200.0)\n","lesion_img_tsne = tsne.fit_transform(lesion_img_flat)\n","\n","colors = ['red', 'blue']\n","classes = [0,1]\n","\n","plot_visualization(lesion_img_tsne,kmeans_labels,colors,classes,\"T-SNE K Means Clustering Representation\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8no7ew-5SXy","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214961,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"Agglomerative Clustering\")\n","aglist = []\n","for i in range(IMGS_TO_CHECK):\n","  lesion_img = X[i]\n","\n","  lesion_img_flat = lesion_img.reshape(lesion_img.shape[0]*lesion_img.shape[1],lesion_img.shape[2])\n","\n","  agglomerative = AgglomerativeClustering(n_clusters=2)\n","  agglomerative_labels = agglomerative.fit_predict(lesion_img_flat)\n","\n","  for j in range(len(agglomerative_labels)):\n","    if agglomerative_labels[j] == 1:\n","      agglomerative_labels[j] = 255\n","\n","  agglomerative_lesion_img = agglomerative_labels.reshape(IMG_HEIGHT,IMG_WIDTH)\n","  aglist.append(agglomerative_lesion_img)\n","\n","def plot_thing(image_index):\n","  lesion_img = X_g[image_index]\n","  agglomerative_lesion_img = aglist[image_index]\n","  cv2_imshow(lesion_img)\n","  cv2_imshow(agglomerative_lesion_img)\n","\n","interact(plot_thing, image_index=widgets.IntSlider(min=0, max=IMGS_TO_CHECK - 1, step=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOEzjQsI4Jlo","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214960,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["lesion_img = X[0]\n","lesion_img_flat = lesion_img.reshape(lesion_img.shape[0]*lesion_img.shape[1],lesion_img.shape[2])\n","\n","agglomerative = AgglomerativeClustering(n_clusters=2)\n","agglomerative_labels = agglomerative.fit_predict(lesion_img_flat)\n","\n","for i in range(len(agglomerative_labels)):\n","  if agglomerative_labels[i] == 1:\n","    agglomerative_labels[i] = 255\n","\n","tsne = TSNE(n_components=2,init=\"random\",learning_rate=200.0)\n","lesion_img_tsne = tsne.fit_transform(lesion_img_flat)\n","\n","colors = ['red', 'blue']\n","classes = [0,1]\n","\n","plot_visualization(lesion_img_tsne,agglomerative_labels,colors,classes,\"T-SNE Agglomerative Clustering Representation\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvacPEFKQi_Z","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214960,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["os.makedirs('images_seg', exist_ok=True)\n","!wget -O images_seg.zip 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/images_seg.zip'\n","!unzip -q images_seg.zip -d images_seg\n","\n","os.makedirs('segmentation', exist_ok=True)\n","!wget -O segmentations.zip 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20B)%20Skin%20Cancer%20Diagnosis/segmentations.zip'\n","!unzip -q segmentations.zip -d segmentation\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUqi2yOXTzx9","executionInfo":{"status":"aborted","timestamp":1687337747176,"user_tz":300,"elapsed":214959,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["IMG_SEG_WIDTH = 256\n","IMG_SEG_HEIGHT = 192"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOUAi97ySnoK","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214959,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_seg = []\n","y_seg = []\n","\n","path, dirs, files = next(os.walk(\"images_seg/Images\"))\n","\n","path, dirs, files_seg = next(os.walk(\"segmentation/Segmentation\"))\n","\n","for i in tqdm(range(len(files))):\n","  file_name = files[i].split('.')[0]\n","  seg_index = [j for j, s in enumerate(files_seg) if file_name in s][0]\n","\n","  img = cv2.imread('images_seg/Images/' + files[i],cv2.IMREAD_COLOR)\n","  img = cv2.resize(img,(IMG_SEG_WIDTH,IMG_SEG_HEIGHT))\n","  img = img/255.0\n","  X_seg.append(img)\n","\n","  img = cv2.imread('segmentation/Segmentation/' + files_seg[seg_index],cv2.IMREAD_COLOR)\n","  img = cv2.resize(img,(IMG_SEG_WIDTH,IMG_SEG_HEIGHT))\n","  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","  img = img/255.0\n","  y_seg.append(img)\n","\n","X_seg = np.array(X_seg)\n","y_seg = np.array(y_seg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aNe6gHQeFCO","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214958,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"Original Image\")\n","cv2_imshow(X_seg[2]*255)\n","print(\"Image Mask\")\n","cv2_imshow(y_seg[2]*255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fv52CAZHVoDD","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214957,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["X_seg_train, X_seg_test, y_seg_train, y_seg_test = train_test_split(X_seg, y_seg, test_size=0.2, random_state=101)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vyFIIvxasuq","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214956,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def build_model():\n","  inputs = Input((IMG_SEG_HEIGHT, IMG_SEG_WIDTH, 3))\n","  s = Lambda(lambda x: x / 255) (inputs)\n","\n","  conv_blocks = [16,32,64,128,256,128,64,32,16]\n","\n","  conv1 = Conv2D(conv_blocks[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n","  conv1 = Dropout(0.1) (conv1)\n","  conv1 = Conv2D(conv_blocks[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1)\n","  pool1 = MaxPooling2D((2, 2)) (conv1)\n","\n","  conv2 = Conv2D(conv_blocks[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool1)\n","  conv2 = Dropout(0.1) (conv2)\n","  conv2 = Conv2D(conv_blocks[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2)\n","  pool2 = MaxPooling2D((2, 2)) (conv2)\n","\n","  conv3 = Conv2D(conv_blocks[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool2)\n","  conv3 = Dropout(0.2) (conv3)\n","  conv3 = Conv2D(conv_blocks[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3)\n","  pool3 = MaxPooling2D((2, 2)) (conv3)\n","\n","  conv4 = Conv2D(conv_blocks[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3)\n","  conv4 = Dropout(0.2) (conv4)\n","  conv4 = Conv2D(conv_blocks[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)\n","  pool4 = MaxPooling2D(pool_size=(2, 2)) (conv4)\n","\n","  conv5 = Conv2D(conv_blocks[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4)\n","  conv5 = Dropout(0.3) (conv5)\n","  conv5 = Conv2D(conv_blocks[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5)\n","\n","  upconv6 = Conv2DTranspose(conv_blocks[5], (2, 2), strides=(2, 2), padding='same') (conv5)\n","  upconv6 = concatenate([upconv6, conv4])\n","  conv6 = Conv2D(conv_blocks[5], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv6)\n","  conv6 = Dropout(0.2) (conv6)\n","  conv6 = Conv2D(conv_blocks[5], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv6)\n","\n","  upconv7 = Conv2DTranspose(conv_blocks[6], (2, 2), strides=(2, 2), padding='same') (conv6)\n","  upconv7 = concatenate([upconv7, conv3])\n","  conv7 = Conv2D(conv_blocks[6], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv7)\n","  conv7 = Dropout(0.2) (conv7)\n","  conv7 = Conv2D(conv_blocks[6], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv7)\n","\n","  upconv8 = Conv2DTranspose(conv_blocks[7], (2, 2), strides=(2, 2), padding='same') (conv7)\n","  upconv8 = concatenate([upconv8, conv2])\n","  conv8 = Conv2D(conv_blocks[7], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv8)\n","  conv8 = Dropout(0.1) (conv8)\n","  conv8 = Conv2D(conv_blocks[7], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv8)\n","\n","  upconv9 = Conv2DTranspose(conv_blocks[8], (2, 2), strides=(2, 2), padding='same') (conv8)\n","  upconv9 = concatenate([upconv9, conv1], axis=3)\n","  conv9 = Conv2D(conv_blocks[8], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv9)\n","  conv9 = Dropout(0.1) (conv9)\n","  conv9 = Conv2D(conv_blocks[8], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv9)\n","\n","  outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv9)\n","\n","  model = Model(inputs=[inputs], outputs=[outputs])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWsZMLIwa7Iq","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214955,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def iou(y_true, y_pred):\n","     def f(y_true, y_pred):\n","         intersection = (y_true * y_pred).sum()\n","         union = y_true.sum() + y_pred.sum() - intersection\n","         x = (intersection + 1e-15) / (union + 1e-15)\n","         x = x.astype(np.float32)\n","         return x\n","     return tf.numpy_function(f, [y_true, y_pred], tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3XHXe2MbBYI","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214954,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["## Hyperparameters\n","batch = 16\n","lr = 1e-4\n","\n","model = build_model()\n","\n","opt = keras.optimizers.Adam(lr)\n","metrics = [iou]\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2o9vg_NIY0r4","executionInfo":{"status":"aborted","timestamp":1687337747177,"user_tz":300,"elapsed":214953,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["model.fit(X_seg_train.astype(np.float32), y_seg_train.astype(np.float32),\n","        validation_data=(X_seg_test.astype(np.float32),y_seg_test.astype(np.float32))\n","        ,epochs=20,verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MO4Pj5BVgaLG","executionInfo":{"status":"aborted","timestamp":1687337747178,"user_tz":300,"elapsed":214953,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["y_seg_pred = model.predict(X_seg_test)\n","iou_val = iou(np.expand_dims(y_seg_test,axis=3),y_seg_pred)\n","print(\"IOU: \" + str(iou_val.numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r40__nJmmHcY","executionInfo":{"status":"aborted","timestamp":1687337747178,"user_tz":300,"elapsed":214952,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["image_index = 27"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTqBJnVDQoAj","executionInfo":{"status":"aborted","timestamp":1687337747178,"user_tz":300,"elapsed":214952,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"Original Image\")\n","cv2_imshow(X_seg_test[image_index]*255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRUJufEOQpVZ","executionInfo":{"status":"aborted","timestamp":1687337747178,"user_tz":300,"elapsed":214950,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"True Segmentation\")\n","cv2_imshow(y_seg_test[image_index]*255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QC43OIsJYmnU","executionInfo":{"status":"aborted","timestamp":1687337747178,"user_tz":300,"elapsed":214949,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["print(\"Predicted Segmentation\")\n","prediction = model.predict(X_seg_test[image_index][None,:])\n","\n","prediction_img = np.reshape(prediction.flatten(),(IMG_SEG_HEIGHT, IMG_SEG_WIDTH))\n","retval, threshold = cv2.threshold(prediction_img, 0.5, 255, cv2.THRESH_BINARY)\n","\n","cv2_imshow(threshold*255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQeuVu4teAQH","executionInfo":{"status":"aborted","timestamp":1687337747179,"user_tz":300,"elapsed":214949,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["def build_model_modified():\n","  inputs = Input((IMG_SEG_HEIGHT, IMG_SEG_WIDTH, 3))\n","  s = Lambda(lambda x: x / 255) (inputs)\n","\n","  # Code below is a copy from the original model code from above as placeholder.\n","\n","  conv_blocks = [16,32,64,128,256,128,64,32,16]\n","\n","  conv1 = Conv2D(conv_blocks[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n","  conv1 = Dropout(0.1) (conv1)\n","  conv1 = Conv2D(conv_blocks[0], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1)\n","  pool1 = MaxPooling2D((2, 2)) (conv1)\n","\n","  conv2 = Conv2D(conv_blocks[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool1)\n","  conv2 = Dropout(0.1) (conv2)\n","  conv2 = Conv2D(conv_blocks[1], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2)\n","  pool2 = MaxPooling2D((2, 2)) (conv2)\n","\n","  conv3 = Conv2D(conv_blocks[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool2)\n","  conv3 = Dropout(0.2) (conv3)\n","  conv3 = Conv2D(conv_blocks[2], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3)\n","  pool3 = MaxPooling2D((2, 2)) (conv3)\n","\n","  conv4 = Conv2D(conv_blocks[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3)\n","  conv4 = Dropout(0.2) (conv4)\n","  conv4 = Conv2D(conv_blocks[3], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4)\n","  pool4 = MaxPooling2D(pool_size=(2, 2)) (conv4)\n","\n","  conv5 = Conv2D(conv_blocks[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4)\n","  conv5 = Dropout(0.3) (conv5)\n","  conv5 = Conv2D(conv_blocks[4], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5)\n","\n","  upconv6 = Conv2DTranspose(conv_blocks[5], (2, 2), strides=(2, 2), padding='same') (conv5)\n","  upconv6 = concatenate([upconv6, conv4])\n","  conv6 = Conv2D(conv_blocks[5], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv6)\n","  conv6 = Dropout(0.2) (conv6)\n","  conv6 = Conv2D(conv_blocks[5], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv6)\n","\n","  upconv7 = Conv2DTranspose(conv_blocks[6], (2, 2), strides=(2, 2), padding='same') (conv6)\n","  upconv7 = concatenate([upconv7, conv3])\n","  conv7 = Conv2D(conv_blocks[6], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv7)\n","  conv7 = Dropout(0.2) (conv7)\n","  conv7 = Conv2D(conv_blocks[6], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv7)\n","\n","  upconv8 = Conv2DTranspose(conv_blocks[7], (2, 2), strides=(2, 2), padding='same') (conv7)\n","  upconv8 = concatenate([upconv8, conv2])\n","  conv8 = Conv2D(conv_blocks[7], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv8)\n","  conv8 = Dropout(0.1) (conv8)\n","  conv8 = Conv2D(conv_blocks[7], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv8)\n","\n","  upconv9 = Conv2DTranspose(conv_blocks[8], (2, 2), strides=(2, 2), padding='same') (conv8)\n","  upconv9 = concatenate([upconv9, conv1], axis=3)\n","  conv9 = Conv2D(conv_blocks[8], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (upconv9)\n","  conv9 = Dropout(0.1) (conv9)\n","  c9 = Conv2D(conv_blocks[8], (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv9)\n","\n","  ###\n","\n","  outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n","\n","  model = Model(inputs=[inputs], outputs=[outputs])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4eIdMVTLbu9","executionInfo":{"status":"aborted","timestamp":1687337747179,"user_tz":300,"elapsed":214948,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["## Hyperparameters\n","batch = 16\n","lr = 1e-4\n","\n","model = build_model_modified()\n","\n","opt = keras.optimizers.Adam(lr)\n","metrics = [iou]\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"et25mb7ZLcBK","executionInfo":{"status":"aborted","timestamp":1687337747179,"user_tz":300,"elapsed":214948,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["model.fit(X_seg_train.astype(np.float32), y_seg_train.astype(np.float32),\n","        validation_data=(X_seg_test.astype(np.float32),y_seg_test.astype(np.float32))\n","        ,epochs=20,verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TVX8eV1LdsK","executionInfo":{"status":"aborted","timestamp":1687337747179,"user_tz":300,"elapsed":214947,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["y_seg_pred = model.predict(X_seg_test)\n","iou_val = iou(np.expand_dims(y_seg_test,axis=3),y_seg_pred)\n","print(\"IOU: \" + str(iou_val.numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rn6879StLkmC","executionInfo":{"status":"aborted","timestamp":1687337747179,"user_tz":300,"elapsed":214946,"user":{"displayName":"Akshaya Sadanala","userId":"04610038736839189969"}}},"source":["image_index = 45\n","\n","print(\"Original Image\")\n","cv2_imshow(X_seg_test[image_index]*255)\n","\n","print(\"True Segmentation\")\n","cv2_imshow(y_seg_test[image_index]*255)\n","\n","print(\"Predicted Segmentation\")\n","prediction = model.predict(X_seg_test[image_index][None,:])\n","\n","prediction_img = np.reshape(prediction.flatten(),(IMG_SEG_HEIGHT, IMG_SEG_WIDTH))\n","retval, threshold = cv2.threshold(prediction_img, 0.5, 255, cv2.THRESH_BINARY)\n","\n","cv2_imshow(threshold*255)"],"execution_count":null,"outputs":[]}]}